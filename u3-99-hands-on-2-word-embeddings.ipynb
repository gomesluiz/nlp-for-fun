{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomesluiz/processamento-de-linguagem-natural/blob/main/u3-99-hands-on-2-word-embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Oh3sCHZU2aY"
      },
      "source": [
        "# BERTimbau\n",
        "Word embeddings sensíveis ao contexto."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instalação dos pacotes necessários\n",
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "yD6LJExwkTvY",
        "outputId": "0ea794d2-45b0-4346-c4a1-9e9e812dd115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlypLoBCU2aZ",
        "outputId": "233231a8-81eb-4a55-b9f6-097fa3a89252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Importações da biblioteca padrão\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForPreTraining\n",
        "from transformers import AutoModel\n",
        "\n",
        "\n",
        "print(\"Pacotes importados com sucesso; notebook pronto para uso!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pacotes importados com sucesso; notebook pronto para uso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declara define funções utilitárias utilizadas no notebook.\n",
        "def formata_msg(nivel, msg):\n",
        "    \"\"\"\n",
        "    Formata uma mensagem de log incluindo o nível de severidade, timestamp\n",
        "    e a mensagem.\n",
        "\n",
        "    Parâmetros:\n",
        "    - nivel (str): Nível de severidade da mensagem (ex: 'INFO', 'ERROR', 'WARNING').\n",
        "    - msg (str): A mensagem de log propriamente dita.\n",
        "\n",
        "    Retorna:\n",
        "    - str: A mensagem de log formatada.\n",
        "    \"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "    return f\"[{nivel}] {timestamp} - {msg}\"\n",
        "\n",
        "\n",
        "print(formata_msg(\"INFO\", \"Funções utilitárias prontas para utilização.\"))\n",
        "print(formata_msg(\"INFO\", f\"Versão do Python: {sys.version} \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW7hmVPuMNbq",
        "outputId": "c5bf94da-255e-40aa-bc46-89bd8612586a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 2024-09-17 03:49:24 - Funções utilitárias prontas para utilização.\n",
            "[INFO] 2024-09-17 03:49:24 - Versão do Python: 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-large-portuguese-cased\", do_lower_case=False)\n",
        "bert = AutoModel.from_pretrained(\"neuralmind/bert-large-portuguese-cased\")\n",
        "bert = bert.to(device)\n",
        "print(formata_msg(\"INFO\", \"BERTimbau carregado com sucesso!\"))"
      ],
      "metadata": {
        "id": "beUgOO5ASa_a",
        "outputId": "3c77ccd0-49b6-4d68-bb6e-b8af49baccdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 2024-09-17 03:49:32 - BERTimbau carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrando o word embedding da palavra gato"
      ],
      "metadata": {
        "id": "E9Dac1HnNR-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Eu vou ao banco pagar a conta hoje\"\n",
        "\n",
        "# tokenizando o texto\n",
        "input_ids = tokenizer.encode(texto, return_tensors=\"pt\")\n",
        "wordpieces = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
        "\n",
        "# salvando ponteiros para palavras\n",
        "subwords_idx = []\n",
        "for i, wordpiece in enumerate(wordpieces):\n",
        "  if \"##\" not in wordpiece and i not in [0, len(wordpieces) -1]:\n",
        "    subwords_idx.append(i)\n",
        "\n",
        "# obtendo os vetores das palavras\n",
        "input_ids = input_ids.to(device)\n",
        "with torch.no_grad():\n",
        "  outs = bert(input_ids)\n",
        "  vetores = outs[0][0, :]"
      ],
      "metadata": {
        "id": "NDUKC1AmFREq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mostrando as palavras semelhantes ao verbo comer."
      ],
      "metadata": {
        "id": "a6quydtFLqh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vetores[subwords_idx].size()"
      ],
      "metadata": {
        "id": "xn6N1h5WEWWU",
        "outputId": "c3460390-d731-4e54-e46d-c62630759f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vetores[subwords_idx][0]"
      ],
      "metadata": {
        "id": "ganbVZXv7uOG",
        "outputId": "d2d136a3-3823-4522-c002-5ca7d7e6ba5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.7010,  0.5676,  0.4165,  ..., -0.3942, -1.0148, -0.4334])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}